{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, BatchNormalization,concatenate,Conv3DTranspose,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = (128,128,128,1)\n",
    "\n",
    "# IC = 32 # INPUT CHANNEL OR FILTERS\n",
    "\n",
    "def UNET_3d_v2 (input_shape=input_shape,IC = 8,last_activation='sigmoid'):\n",
    "    inputs=Input(shape=input_shape)\n",
    "\n",
    "    conv1 = Conv3D(IC,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    d1=Dropout(0.1)(conv1)\n",
    "    conv2 = Conv3D(IC,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d1)\n",
    "    b=BatchNormalization()(conv2)\n",
    "\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2,2))(b)\n",
    "    conv3 = Conv3D(IC*2,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    d2=Dropout(0.2)(conv3)\n",
    "    conv4 = Conv3D(IC*2,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d2)\n",
    "    b1=BatchNormalization()(conv4)\n",
    "\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(b1)\n",
    "    conv5 = Conv3D(IC*4,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    d3=Dropout(0.3)(conv5)\n",
    "    conv6 = Conv3D(IC*4,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d3)\n",
    "    b2=BatchNormalization()(conv6)\n",
    "\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(b2)\n",
    "    conv7 = Conv3D(IC*8,(3,3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    d4=Dropout(0.4)(conv7)\n",
    "    conv8 = Conv3D(IC*8,(3,3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d4)\n",
    "    b3=BatchNormalization()(conv8)\n",
    "\n",
    "    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(b3)\n",
    "    conv9 = Conv3D(IC*16,(3,3, 3),activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    d5=Dropout(0.5)(conv9)\n",
    "    conv10 = Conv3D(IC*16,(3,3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d5)\n",
    "    b4=BatchNormalization()(conv10)\n",
    "\n",
    "\n",
    "    conv11 = Conv3DTranspose(IC*16,(4,4, 4), activation = 'relu', padding = 'same', strides=(2,2, 2),kernel_initializer = 'he_normal')(b4)\n",
    "    x= concatenate([conv11,conv8])\n",
    "    conv12 = Conv3D(IC*8,(3,3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
    "    d6=Dropout(0.4)(conv12)\n",
    "    conv13 = Conv3D(IC*8,(3,3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d6)\n",
    "    b5=BatchNormalization()(conv13)\n",
    "\n",
    "\n",
    "    conv14 = Conv3DTranspose(IC*8,(4,4, 4), activation = 'relu', padding = 'same', strides=(2,2, 2),kernel_initializer = 'he_normal')(b5)\n",
    "    x1=concatenate([conv14,conv6])\n",
    "    conv15 = Conv3D(IC*4,3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x1)\n",
    "    d7=Dropout(0.3)(conv15)\n",
    "    conv16 = Conv3D(IC*4,3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d7)\n",
    "    b6=BatchNormalization()(conv16)\n",
    "\n",
    "    conv17 = Conv3DTranspose(IC*4,(4,4,4), activation = 'relu', padding = 'same',strides=(2,2, 2), kernel_initializer = 'he_normal')(b6)\n",
    "    x2=concatenate([conv17,conv4])\n",
    "    conv18 = Conv3D(IC*2,(3,3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x2)\n",
    "    d8=Dropout(0.2)(conv18)\n",
    "    conv19 = Conv3D(IC*2,(3,3, 3) ,activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d8)\n",
    "    b7=BatchNormalization()(conv19)\n",
    "\n",
    "    conv20 = Conv3DTranspose(IC*2,(4,4, 4), activation = 'relu', padding = 'same',strides=(2,2, 2), kernel_initializer = 'he_normal')(b7)\n",
    "    x3=concatenate([conv20,conv2])\n",
    "    conv21 = Conv3D(IC,(3,3 , 3) ,activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x3)\n",
    "    d9=Dropout(0.1)(conv21)\n",
    "    conv22 = Conv3D(IC,(3,3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d9)\n",
    "\n",
    "    outputs = Conv3D(1,(1,1, 1), activation = last_activation, padding = 'same', kernel_initializer = 'he_normal')(conv22)\n",
    "    model = Model( inputs = inputs, outputs = outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "lab_dir = './data_CBCT/labels/'\n",
    "fd_img = './data_CBCT/images/'\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import skimage.transform as skTrans\n",
    "\n",
    "def preprocess_data_cbct(folder_directory, desired_shape=(128,128,128)):\n",
    "    # Get the list of all files in the directory\n",
    "    files = os.listdir(folder_directory)\n",
    "\n",
    "    # Create an empty list to store the preprocessed data arrays\n",
    "    preprocessed_data = []\n",
    "\n",
    "    # Load each file and preprocess the data\n",
    "    for file_name in files:\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_directory, file_name)\n",
    "\n",
    "        # Load the file\n",
    "        nii_data = nib.load(file_path)\n",
    "\n",
    "        # Access the data array\n",
    "        data_array = nii_data.get_fdata()\n",
    "        # skTrans.resize will resize the image to (400,400,280). But if we use np.resize the the output \n",
    "        # images for some file will be blank if there sizes are not (400,400,280).\n",
    "#         data_array = skTrans.resize(data_array, (400,400,280), order=1, preserve_range=True)\n",
    "\n",
    "#         # Check if the data array shape matches the desired shape\n",
    "        if data_array.shape != desired_shape:\n",
    "        \n",
    "#             # Reshape the data array to the desired shape\n",
    "#              data_array = skTrans.resize(data_array, desired_shape, order=1, preserve_range=True)\n",
    "             data_array = skTrans.resize(data_array, desired_shape,  mode = 'constant', order=0, preserve_range=False, anti_aliasing=False)\n",
    "\n",
    "        # Normalize the data array\n",
    "        data_array = (data_array - np.min(data_array)) / (np.max(data_array) - np.min(data_array))\n",
    "        data_array = np.asarray(data_array)\n",
    "        # Convert the data array to float32\n",
    "        data_array = data_array.astype(np.float32)\n",
    "        \n",
    "\n",
    "        # Add a new axis to the data array to represent the channel dimension\n",
    "        data_array = np.expand_dims(data_array, axis=-1)\n",
    "\n",
    "        # Append the preprocessed data array to the list\n",
    "        preprocessed_data.append(data_array)\n",
    "\n",
    "    # Convert the preprocessed data list to a numpy array\n",
    "    preprocessed_data = np.array(preprocessed_data)\n",
    "\n",
    "    return preprocessed_data\n",
    "\n",
    "X = preprocess_data_cbct(fd_img,desired_shape=(128,128,128))\n",
    "Y = preprocess_data_cbct(lab_dir,desired_shape=(128,128,128))\n",
    "\n",
    "x_train = X[:100,:,:,:,:]\n",
    "y_train = Y[:100,:,:,:,:]\n",
    "x_test = X[100:,:,:,:,:]\n",
    "y_test = Y[100:,:,:,:,:]\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\",\"/gpu:4\",\"/gpu:5\",\"/gpu:6\",\"/gpu:7\"])\n",
    "\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    model =UNET_3d_v2(input_shape=(128,128,128,1),IC = 8,last_activation='sigmoid')\n",
    "\n",
    "    # model.summary()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, batch_size = 1, epochs=100,validation_split=0.2, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bkp_image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
